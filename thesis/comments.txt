Thesis notes


Should the order of the decorators matter? all except in one case, they're written in a way that the order doesn't matter even with the original semantics of decorators. In that one case, it cannot be written in that way. Instead of correcting a user's error, there's a mechanism looking for this error and the user is notified. Guessing the unspecified is cool, but correcting the wrong is not

✅ hot-reload
✅ Extract doc comment from function with markdown
✅ Evaluate endpoint
✅ body instead of query
✅ automatically find parameters
✅ Generic return types
✅  Data engineer notebook, ds notebook, deployment script
✅ Nice error handling
✅ notebook support
✅ Evaluation result return type that contains explanation - explanation field
✅ largefiles mongo backend
✅ Fix endpoints
✅ Bug: should recreate table
✅ Mongo, Create index for each encountered field - async
✅ Save test/train data - tags and ground truth classifier?
✅ Handle multiple great ai instances
✅ create_shadow_deployment -> traceId, evaluationId

Show model accuracy statistics
Test entry point function -> with expected error rate

Show data distribution - buttons in header?

Cannot be installed -> save model card, https://github.com/tensorflow/model-card-toolkit

Cannot use google-research/robustness_metrics Only works for TF

Why do I have a complex example, it's supposed to be a simple library
Argumetn/parameter names were confusing

For example: large file is easy to replace, the decisions are found by the best practices table and highlighted on the dashboard

During development, I wanted to check out which types of request fail -> log errors in traces
Even production systems are not perfect, saving and letting the users filter on the errors is useful. e.g. they can correlate it with the input

Should the order of the decorators matter? all except in one case, they're written in a way that the order doesn't matter even with the original semantics of decorators. In that one case, it cannot be written in that way. Instead of correcting a user's error, there's a mechanism looking for this error and the user is notified. Guessing the unspecified is cool, but correcting the wrong is not

Users like sonar checks, ci/cd, docker files, makes the project seem more trustworthy, also provides integration for them

Leslie Lamport: problems are difficult to find at a research h table, they come from practice

%matplotlib inline is called automatically on first draw, very confusing as it resets the rcParams, you have to set them twice, like come on

 Have to explicitly write version="latest" to signify that it can change any time someone uploads a new model

offline_mode -> cache_only_mode 

--------------------------------------------

Design science methodology for information systems and software engineering \cite{wieringa2014design}

design science research are design problems through its research method, the design cycle

Design science is the design and investigation of artifacts in context

Help a class of stakeholders

e, we outline a research agenda for AI engineering research to help the research community structure and conceptualize the problem space.
]. In addition to this, model deployment is a highly underestimated area [3].
￼

Unfortunately, our research [3]–[5] shows that the transition from prototype to production-quality deployment of ML models proves to be challenging for many companies.

AI engineering (which we define as an extension of Software Engineering with new processes and technologies needed for development and evolution of AI systems
a set of 16 primary cases as the foundation for the challenges we identify and the research agenda we outline.

cases representing startups as well as large multinational companies in domains such as e.g. real estate, weather forecasting, fraud detection, sentiment analysis and failure prediction

we outline a research agenda for AI engineering research to help the research community structure and conceptualize the problem space

significant additional functionality is required to ensure that the ML/DL model can operate in a reliable and predictable fashion with proper engineering of data pipelines, monitoring and logging, etc. [2], [11]. T

Instead, we provide an overview in figure 2 and present a categorization of the identified problems in four strategic focus areas, relating to the typical phases of a ML project. These four areas are the following:
￼

AI Lifecycle Models Need To Be Revised \cite{haakman2021ai}

Fintech - ING

We have found that the following stages have been overlooked by previous lifecycle models: data collection, feasibility study, documentation, model monitoring, and model risk assessment.
more focus is needed on the entire lifecycle. In particular, regardless of the existing development tools for Machine Learning, we observe that they are still not meeting the particularities of this field.

Cross-Industry Standard Process for Data Mining (CRISP-DM) [39] and the Team Data Science Process (TDSP)
\cite{wirth2000crisp}
https://docs.microsoft.com/en-us/azure/architecture/data-science-process/overview

What if you just use huggingface?

"it is hard to isolate two different machine learning models that operate in the same systemA – often they ought to be developed and training together"

For example, the team of P08 keeps track of an experiment log using a spreadsheet, in which the training set, validation set, model, and preprocessing steps are specified for each version. This approach for versioning is preferred over solutions like MLFlow7 for the sake of simplicity

Teams resort to self-developed or highly-customized dashboard platforms to monitor the models (P15, P16)

Researchers could focus on solving the reported challenges in the Machine Learning lifecycle with additional tool support and reveal challenges of the ML lifecycle in other domains by extending the case study to more organizations and different types of industries 
Our study shows that, despite the increasing trend on improving the state-of-the-art model training techniques, there is a research gap on the challenges of developing real-world machine learning systems. F

It is also necessary to create holistic monitoring solutions that can scale to different models in an organization
￼


AI Deployment Architecture: Multi-Case Study for Key Factor Identification
According to [12] and [13], developing, deploying and maintaining complex commercial ML-based system is a challenging task. Most ML-based systems have strict latency requirements at inference stage [14]. Training-serving skew also results in sub-optimal model performance [15]. For the realistic implementation of ML, there is a need to consider and adapt well established SE practices which have been ignored or had a very narrow focus in ML literature [16] [17].

Software Engineering for Machine Learning: A Case Study 

MicrosoftE

Automation is a vital cross-cutting concern

Automating tests is as important in machine learning as it is in software engineering; teams create carefully put-together test sets that capture what their models should do. However, it is important that a human remains in the loop. One respondent said, “we spot check and have a human look at the errors to see why this particular category is not doing well, and then hypothesize to figure out problem source.”

In addition, respondents with low experience rank challenges with integrating AI into larger systems higher than those with medium or high experience. 

. Software engineers prefer to design and build systems which are elegant, abstract, modular, and simple. By contrast, the data used in machine learning are voluminous, context-specific, heterogeneous, and often complex to describe. These differences result in difficult problems when ML models are integrated into software systems at scale.

---

[3] AI components can be entangled in complex ways
. Thus, even if separate teams built each model, they would have to collaborate closely in order to properly train or maintain the full system. This phenomenon (also referred to as component entanglement) can lead to non-monotonic error propagation, meaning that improvements in one part of the system might decrease the overall system quality because the rest of the system is not tuned to the latest improvements.

Ethics guidelines for trustworthy AI

https://digital-strategy.ec.europa.eu/en/library/ethics-guidelines-trustworthy-ai

> (3) robust - both from a technical perspective while taking into account its social environment

7 key requirements
Human agency and oversight:
Technical Robustness and safety: 
Transparency
Accountability

Understanding Development Process of Machine Learning Systems: Challenges and Solutions \cite{de2019understanding}

Given that several ML system development companies are either startups or small companies with few developers, it is of utmost importance to understand the needs and challenges of developers working in these small organizations.

ns. However, there is a gap in understanding how professionals develop ML systems in small and local companies. 
￼
￼
Versioning for End-to-End Machine Learning Pipelines \cite{van2017versioning}
Highlights the importance of schema versioning in an environment of rapidly changing models and transformations

Adoption and Effects of Software Engineering Best FinaPractices in Machine Learning \cite{serban2020adoption}
aim: determine the state of the art in how teams develop, deploy and maintain software with ML components.

t traditional software engineering practices tend to have lower adoption than ML specific practices

distilled a set of 29 engineering best practices

For example, our results suggest that traceability would benefit most from increased adoption of practice 25, the logging of production predictions with model versions and input data.

Practices for Engineering Trustworthy Machine Learning Applications \cite{serban2021practices}

the negative impact that improper use of ML can have on users and society is now also widely recognised

In total, we identified 14 new practices, and used them to complement an existing catalogue of ML engineering practices.

Well-intentioned but improper development of ML components can cause unintentional harm [2].

trustworthy ML is relatively low.

clearly reflect a desire for ML components to be lawful, ethical and robust [1]. H

In this paper, we aim to bridge the gap between guidelines from policy makers and operational practices for developers and their immediate collaborators.

￼
However, none of these lines of work tackle issues related to the negative impact that improper use of ML has on society


We also believe that the adoption of trustworthiness-specific and general ML engineering practices is interconnected; for instance, the practice of continuous integration [6] can make the practices for bias testing more effective.
