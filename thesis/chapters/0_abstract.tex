\begin{abstract}

\absdiv{Background}
Despite its long-standing history, artificial intelligence (AI) has only recently started enjoying widespread industry awareness and adoption; partly thanks to the prevalence of accessible frameworks exposing state-of-the-art models through simple API-s. However, in order to achieve robust deployments, the successful integration of AI components demands strong engineering methods. Concerningly, a tendency seems to be unfolding: even though industry professionals already have access to numerous frameworks for deploying AI correctly and responsibly, case-studies and developer surveys have found that a considerable fraction of deployments do not follow best practices.
\absdiv{Objective}
This thesis sets out to investigate the reasons behind the asymmetry between the adoption of accessible AI libraries and preexisting reusable solutions to robust deployments. A software framework called \textit{GreatAI} is designed which aims to facilitate \underline{G}eneral \underline{R}obust \underline{E}nd-to-end \underline{A}utomated \underline{T}rustworthy AI deployments while attempting to overcome the practical drawbacks of similar, existing frameworks.
\absdiv{Method}
The utility of \textit{GreatAI} is validated using the principles of design science methodology through iteratively designing its API and implementation along with the text mining pipeline of a commercial product. Subsequently, interviews are conducted among practitioners for validating the generalisability of the design.
\absdiv{Results}
To do.
\absdiv{Conclusions}
To do.

\keywords{SE4ML \and AI engineering \and Trustworthy AI \and Deployment \and Text mining}

\end{abstract}
