{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Harden and deploy your app\n",
    "\n",
    "Finally, it's time to deploy your model. But before you have to make sure you follow AI deployment [best-practices](https://se-ml.github.io/). In the past, this step was too often either the source of unexpected struggles, or worse, simply ignored.\n",
    "\n",
    "With `GreatAI`, it has become a matter of 2 lines of code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;226m2022-07-09 22:38:56 |  WARNING | Environment variable ENVIRONMENT is not set, defaulting to development mode ‼️\u001b[0m\n",
      "\u001b[38;5;226m2022-07-09 22:38:56 |  WARNING | Cannot find credentials files, defaulting to using ParallelTinyDbDriver\u001b[0m\n",
      "\u001b[38;5;226m2022-07-09 22:38:56 |  WARNING | The selected tracing database (ParallelTinyDbDriver) is not recommended for production\u001b[0m\n",
      "\u001b[38;5;226m2022-07-09 22:38:56 |  WARNING | Cannot find credentials files, defaulting to using LargeFileLocal\u001b[0m\n",
      "\u001b[38;5;39m2022-07-09 22:38:56 |     INFO | GreatAI (v0.1.0): configured ✅\u001b[0m\n",
      "\u001b[38;5;39m2022-07-09 22:38:56 |     INFO |   🔩 tracing_database: ParallelTinyDbDriver\u001b[0m\n",
      "\u001b[38;5;39m2022-07-09 22:38:56 |     INFO |   🔩 large_file_implementation: LargeFileLocal\u001b[0m\n",
      "\u001b[38;5;39m2022-07-09 22:38:56 |     INFO |   🔩 is_production: False\u001b[0m\n",
      "\u001b[38;5;39m2022-07-09 22:38:56 |     INFO |   🔩 should_log_exception_stack: True\u001b[0m\n",
      "\u001b[38;5;39m2022-07-09 22:38:56 |     INFO |   🔩 prediction_cache_size: 512\u001b[0m\n",
      "\u001b[38;5;39m2022-07-09 22:38:56 |     INFO |   🔩 dashboard_table_size: 20\u001b[0m\n",
      "\u001b[38;5;226m2022-07-09 22:38:56 |  WARNING | You still need to check whether you follow all best practices before trusting your deployment.\u001b[0m\n",
      "\u001b[38;5;226m2022-07-09 22:38:56 |  WARNING | > Find out more at https://se-ml.github.io/practices\u001b[0m\n",
      "\u001b[38;5;39m2022-07-09 22:38:56 |     INFO | Fetching cached versions of my-domain-predictor\u001b[0m\n",
      "\u001b[38;5;39m2022-07-09 22:38:56 |     INFO | Latest version of my-domain-predictor is 5 (from versions: 0, 1, 2, 3, 4, 5)\u001b[0m\n",
      "\u001b[38;5;39m2022-07-09 22:38:56 |     INFO | File my-domain-predictor-5 found in cache\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from great_ai import GreatAI, use_model\n",
    "from great_ai.utilities import clean\n",
    "\n",
    "\n",
    "@GreatAI.create\n",
    "@use_model(\"my-domain-predictor\")\n",
    "def predict_domain(sentence, model):\n",
    "    inputs = [clean(sentence)]\n",
    "    return str(model.predict(inputs)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Trace[str]({ 'created': '2022-07-09T20:38:56.394746',\n",
       "  'exception': None,\n",
       "  'feedback': None,\n",
       "  'logged_values': { 'arg:sentence:length': 29,\n",
       "                     'arg:sentence:value': 'Mountains are just big rocks.'},\n",
       "  'models': [{'key': 'my-domain-predictor', 'version': 5}],\n",
       "  'original_execution_time_ms': 4.999,\n",
       "  'output': 'geography',\n",
       "  'tags': ['predict_domain', 'online', 'development'],\n",
       "  'trace_id': 'aad1f83d-a81f-4b8b-898e-d02f8076616f'})"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_domain(\"Mountains are just big rocks.\")\n",
    "# the original return value is under the 'output' key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;39m2022-07-09 22:38:58 |     INFO | Converting notebook to Python script\u001b[0m\n",
      "\u001b[38;5;39m2022-07-09 22:38:58 |     INFO | Found `predict_domain` to be the GreatAI app \u001b[0m\n",
      "\u001b[38;5;39m2022-07-09 22:38:58 |     INFO | Uvicorn running on http://0.0.0.0:6060 (Press CTRL+C to quit)\u001b[0m\n",
      "\u001b[38;5;226m2022-07-09 22:39:00 |  WARNING | Environment variable ENVIRONMENT is not set, defaulting to development mode ‼️\u001b[0m\n",
      "\u001b[38;5;226m2022-07-09 22:39:00 |  WARNING | Cannot find credentials files, defaulting to using ParallelTinyDbDriver\u001b[0m\n",
      "\u001b[38;5;226m2022-07-09 22:39:00 |  WARNING | The selected tracing database (ParallelTinyDbDriver) is not recommended for production\u001b[0m\n",
      "\u001b[38;5;226m2022-07-09 22:39:00 |  WARNING | Cannot find credentials files, defaulting to using LargeFileLocal\u001b[0m\n",
      "\u001b[38;5;39m2022-07-09 22:39:00 |     INFO | GreatAI (v0.1.0): configured ✅\u001b[0m\n",
      "\u001b[38;5;39m2022-07-09 22:39:00 |     INFO |   🔩 tracing_database: ParallelTinyDbDriver\u001b[0m\n",
      "\u001b[38;5;39m2022-07-09 22:39:00 |     INFO |   🔩 large_file_implementation: LargeFileLocal\u001b[0m\n",
      "\u001b[38;5;39m2022-07-09 22:39:00 |     INFO |   🔩 is_production: False\u001b[0m\n",
      "\u001b[38;5;39m2022-07-09 22:39:00 |     INFO |   🔩 should_log_exception_stack: True\u001b[0m\n",
      "\u001b[38;5;39m2022-07-09 22:39:00 |     INFO |   🔩 prediction_cache_size: 512\u001b[0m\n",
      "\u001b[38;5;39m2022-07-09 22:39:00 |     INFO |   🔩 dashboard_table_size: 20\u001b[0m\n",
      "\u001b[38;5;226m2022-07-09 22:39:00 |  WARNING | You still need to check whether you follow all best practices before trusting your deployment.\u001b[0m\n",
      "\u001b[38;5;226m2022-07-09 22:39:00 |  WARNING | > Find out more at https://se-ml.github.io/practices\u001b[0m\n",
      "\u001b[38;5;39m2022-07-09 22:39:00 |     INFO | Fetching cached versions of my-domain-predictor\u001b[0m\n",
      "\u001b[38;5;39m2022-07-09 22:39:00 |     INFO | Latest version of my-domain-predictor is 5 (from versions: 0, 1, 2, 3, 4, 5)\u001b[0m\n",
      "\u001b[38;5;39m2022-07-09 22:39:00 |     INFO | File my-domain-predictor-5 found in cache\u001b[0m\n",
      "\u001b[38;5;39m2022-07-09 22:39:00 |     INFO | Started server process [882179]\u001b[0m\n",
      "\u001b[38;5;39m2022-07-09 22:39:00 |     INFO | Waiting for application startup.\u001b[0m\n",
      "\u001b[38;5;39m2022-07-09 22:39:00 |     INFO | Application startup complete.\u001b[0m\n",
      "^C\n",
      "\u001b[38;5;39m2022-07-09 22:39:04 |     INFO | Shutting down\u001b[0m\n",
      "\u001b[38;5;39m2022-07-09 22:39:04 |     INFO | Waiting for application shutdown.\u001b[0m\n",
      "\u001b[38;5;39m2022-07-09 22:39:04 |     INFO | Application shutdown complete.\u001b[0m\n",
      "\u001b[38;5;39m2022-07-09 22:39:04 |     INFO | Finished server process [882179]\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!great-ai deploy.ipynb\n",
    "# leave this running and open http://127.0.0.1:6060"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that you've made sure your application is hardened enough for the intended use case, it is time to deploy it. The responsibilities of GreatAI end when it wraps your inference function and model into a production-ready service. You're given the freedom and responsibility to deploy this service. Fortunately, you (or your organisation) probably already has an established routine for deploying services.\n",
    "\n",
    "There are three main approaches to deploy a GreatAI service: For more info about them, check out [the deployment how-to](/how-to-guides/use-service)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Go back to the summary](/tutorial)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('.env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "02dd6d3afbfa9fbbe1037d64ad9014965528a1ccad21929d6e72f466389a68ad"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
