{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Harden and deploy your app\n",
    "\n",
    "Finally, it's time to deploy your model. But before that, you have to make sure you follow AI deployment [best practices](https://se-ml.github.io/). In the past, this step was too often either the source of unexpected struggle, or worse, simply ignored.\n",
    "\n",
    "With `GreatAI`, it has become a matter of 4 lines of code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;226mEnvironment variable ENVIRONMENT is not set, defaulting to development mode ‼️\u001b[0m\n",
      "\u001b[38;5;226mCannot find credentials files, defaulting to using ParallelTinyDbDriver\u001b[0m\n",
      "\u001b[38;5;226mThe selected tracing database (ParallelTinyDbDriver) is not recommended for production\u001b[0m\n",
      "\u001b[38;5;226mCannot find credentials files, defaulting to using LargeFileLocal\u001b[0m\n",
      "\u001b[38;5;39mGreatAI (v0.1.4): configured ✅\u001b[0m\n",
      "\u001b[38;5;39m  🔩 tracing_database: ParallelTinyDbDriver\u001b[0m\n",
      "\u001b[38;5;39m  🔩 large_file_implementation: LargeFileLocal\u001b[0m\n",
      "\u001b[38;5;39m  🔩 is_production: False\u001b[0m\n",
      "\u001b[38;5;39m  🔩 should_log_exception_stack: True\u001b[0m\n",
      "\u001b[38;5;39m  🔩 prediction_cache_size: 512\u001b[0m\n",
      "\u001b[38;5;39m  🔩 dashboard_table_size: 50\u001b[0m\n",
      "\u001b[38;5;226mYou still need to check whether you follow all best practices before trusting your deployment.\u001b[0m\n",
      "\u001b[38;5;226m> Find out more at https://se-ml.github.io/practices\u001b[0m\n",
      "\u001b[38;5;39mFetching cached versions of my-domain-predictor\u001b[0m\n",
      "\u001b[38;5;39mLatest version of my-domain-predictor is 9 (from versions: 0, 1, 2, 3, 4, 5, 6, 7, 8, 9)\u001b[0m\n",
      "\u001b[38;5;39mFile my-domain-predictor-9 found in cache\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from great_ai import GreatAI, use_model\n",
    "from great_ai.utilities import clean\n",
    "\n",
    "\n",
    "@GreatAI.create\n",
    "@use_model(\"my-domain-predictor\")\n",
    "def predict_domain(sentence, model):\n",
    "    inputs = [clean(sentence)]\n",
    "    return str(model.predict(inputs)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Trace[str]({'created': '2022-07-12T13:34:26.743292',\n",
       "  'exception': None,\n",
       "  'feedback': None,\n",
       "  'logged_values': { 'arg:sentence:length': 29,\n",
       "                     'arg:sentence:value': 'Mountains are just big rocks.'},\n",
       "  'models': [{'key': 'my-domain-predictor', 'version': 9}],\n",
       "  'original_execution_time_ms': 6.9699,\n",
       "  'output': 'geography',\n",
       "  'tags': ['predict_domain', 'online', 'development'],\n",
       "  'trace_id': 'c80bdee3-602b-49dd-a84d-6eef80127e5a'})"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_domain(\"Mountains are just big rocks.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice how the original return value is under the `.output` key. Additionally, a plethora of metadata has been added which will be useful later on.\n",
    "\n",
    "Running your app in development-mode is as easy as executing `great-ai deploy.ipynb` from your terminal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;39m2022-07-12 15:34:28 |     INFO | Converting notebook to Python script\u001b[0m\n",
      "\u001b[38;5;39m2022-07-12 15:34:29 |     INFO | Found `predict_domain` to be the GreatAI app \u001b[0m\n",
      "\u001b[38;5;39m2022-07-12 15:34:29 |     INFO | Uvicorn running on http://0.0.0.0:6060 (Press CTRL+C to quit)\u001b[0m\n",
      "\u001b[38;5;226m2022-07-12 15:34:31 |  WARNING | Environment variable ENVIRONMENT is not set, defaulting to development mode ‼️\u001b[0m\n",
      "\u001b[38;5;226m2022-07-12 15:34:31 |  WARNING | Cannot find credentials files, defaulting to using ParallelTinyDbDriver\u001b[0m\n",
      "\u001b[38;5;226m2022-07-12 15:34:31 |  WARNING | The selected tracing database (ParallelTinyDbDriver) is not recommended for production\u001b[0m\n",
      "\u001b[38;5;226m2022-07-12 15:34:31 |  WARNING | Cannot find credentials files, defaulting to using LargeFileLocal\u001b[0m\n",
      "\u001b[38;5;39m2022-07-12 15:34:31 |     INFO | GreatAI (v0.1.4): configured ✅\u001b[0m\n",
      "\u001b[38;5;39m2022-07-12 15:34:31 |     INFO |   🔩 tracing_database: ParallelTinyDbDriver\u001b[0m\n",
      "\u001b[38;5;39m2022-07-12 15:34:31 |     INFO |   🔩 large_file_implementation: LargeFileLocal\u001b[0m\n",
      "\u001b[38;5;39m2022-07-12 15:34:31 |     INFO |   🔩 is_production: False\u001b[0m\n",
      "\u001b[38;5;39m2022-07-12 15:34:31 |     INFO |   🔩 should_log_exception_stack: True\u001b[0m\n",
      "\u001b[38;5;39m2022-07-12 15:34:31 |     INFO |   🔩 prediction_cache_size: 512\u001b[0m\n",
      "\u001b[38;5;39m2022-07-12 15:34:31 |     INFO |   🔩 dashboard_table_size: 50\u001b[0m\n",
      "\u001b[38;5;226m2022-07-12 15:34:31 |  WARNING | You still need to check whether you follow all best practices before trusting your deployment.\u001b[0m\n",
      "\u001b[38;5;226m2022-07-12 15:34:31 |  WARNING | > Find out more at https://se-ml.github.io/practices\u001b[0m\n",
      "\u001b[38;5;39m2022-07-12 15:34:31 |     INFO | Fetching cached versions of my-domain-predictor\u001b[0m\n",
      "\u001b[38;5;39m2022-07-12 15:34:31 |     INFO | Latest version of my-domain-predictor is 9 (from versions: 0, 1, 2, 3, 4, 5, 6, 7, 8, 9)\u001b[0m\n",
      "\u001b[38;5;39m2022-07-12 15:34:31 |     INFO | File my-domain-predictor-9 found in cache\u001b[0m\n",
      "\u001b[38;5;39m2022-07-12 15:34:31 |     INFO | Started server process [199794]\u001b[0m\n",
      "\u001b[38;5;39m2022-07-12 15:34:31 |     INFO | Waiting for application startup.\u001b[0m\n",
      "\u001b[38;5;39m2022-07-12 15:34:31 |     INFO | Application startup complete.\u001b[0m\n",
      "^C\n",
      "\u001b[38;5;39m2022-07-12 15:34:33 |     INFO | Shutting down\u001b[0m\n",
      "\u001b[38;5;39m2022-07-12 15:34:33 |     INFO | Waiting for application shutdown.\u001b[0m\n",
      "\u001b[38;5;39m2022-07-12 15:34:33 |     INFO | Application shutdown complete.\u001b[0m\n",
      "\u001b[38;5;39m2022-07-12 15:34:33 |     INFO | Finished server process [199794]\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!great-ai deploy.ipynb\n",
    "# leave this running and open http://127.0.0.1:6060"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Congrats, you've just created your first GreatAI service! 🎉\n",
    "\n",
    "Now that you've made sure your application is hardened enough for the intended use case, it is time to deploy it. The responsibilities of GreatAI end when it wraps your inference function and model into a production-ready service. You're given the freedom and responsibility to deploy this service. Fortunately, you (or your organisation) probably already have an established routine for deploying services.\n",
    "\n",
    "There are three main approaches to deploy a GreatAI service: For more info about them, check out [the deployment how-to](/how-to-guides/use-service).\n",
    "\n",
    "For more thorough examples, see the [examples page](/examples/simple/data).\n",
    "\n",
    "### [Go back to the summary](/tutorial/#summary)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('.env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "02dd6d3afbfa9fbbe1037d64ad9014965528a1ccad21929d6e72f466389a68ad"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
